{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "227f7630",
   "metadata": {},
   "source": [
    "# Andrew Kim\n",
    "\n",
    "# ADS 509-01-SU23: Applied Text Mining\n",
    "\n",
    "# Assignment 2.1: Tokenization, Normalization, and Descriptive Statistics\n",
    "\n",
    "# 5/22/2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f79baf9",
   "metadata": {},
   "source": [
    "This notebook holds Assignment 2.1 for Module 2 in ADS 509, Applied Text Mining. Work through this notebook, writing code and answering questions where required. \n",
    "\n",
    "In the previous assignment, you put together Twitter data and lyrics data on two artists. In this assignment, we explore some of the textual features of those data sets. If, for some reason, you did not complete that previous assignment, data to use for this assignment can be found in the assignment materials section of Blackboard. \n",
    "\n",
    "This assignment asks you to write a short function to calculate some descriptive statistics on a piece of text. Then you are asked to find some interesting and unique statistics on your corpora. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae8e2e1",
   "metadata": {},
   "source": [
    "## General Assignment Instructions\n",
    "\n",
    "These instructions are included in every assignment, to remind you of the coding standards for the class. Feel free to delete this cell after reading it. \n",
    "\n",
    "One sign of mature code is conforming to a style guide. We recommend the [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html). If you use a different style guide, please include a cell with a link. \n",
    "\n",
    "Your code should be relatively easy-to-read, sensibly commented, and clean. Writing code is a messy process, so please be sure to edit your final submission. Remove any cells that are not needed or parts of cells that contain unnecessary code. Remove inessential `import` statements and make sure that all such statements are moved into the designated cell. \n",
    "\n",
    "Make use of non-code cells for written commentary. These cells should be grammatical and clearly written. In some of these cells you will have questions to answer. The questions will be marked by a \"Q:\" and will have a corresponding \"A:\" spot for you. *Make sure to answer every question marked with a `Q:` for full credit.* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2d096b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required packages\n",
    "import os\n",
    "import re\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "sw = stopwords.words(\"english\")\n",
    "\n",
    "# Add any additional import statements you need here\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "923b5a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change `data_location` to the location of the folder on your machine.\n",
    "data_location = \"C:/Users/andre/OneDrive/Documents/ADS509/textrepo/\"\n",
    "\n",
    "# These subfolders should still work if you correctly stored the data from the Module 1 assignment\n",
    "twitter_folder = \"twitter/\"\n",
    "lyrics_folder = \"lyrics/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06522af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptive_stats(tokens, num_tokens = 5, verbose=True) :\n",
    "    \"\"\"\n",
    "        Given a list of tokens, print number of tokens, number of unique tokens, \n",
    "        number of characters, lexical diversity (https://en.wikipedia.org/wiki/Lexical_diversity), \n",
    "        and num_tokens most common tokens. Return a list with the number of tokens, number\n",
    "        of unique tokens, lexical diversity, and number of characters. \n",
    "    \n",
    "    \"\"\"\n",
    "    # Fill in the correct values here. \n",
    "    num_tokens = len(tokens)\n",
    "    num_unique_tokens = len(set(tokens))\n",
    "    lexical_diversity = num_unique_tokens/num_tokens\n",
    "    num_characters = sum(len(i) for i in tokens)\n",
    "    \n",
    "    if verbose :        \n",
    "        print(f\"There are {num_tokens} tokens in the data.\")\n",
    "        print(f\"There are {num_unique_tokens} unique tokens in the data.\")\n",
    "        print(f\"There are {num_characters} characters in the data.\")\n",
    "        print(f\"The lexical diversity is {lexical_diversity:.3f} in the data.\")\n",
    "    \n",
    "        # print the five most common tokens\n",
    "        c = Counter(tokens)\n",
    "        top_five = c.most_common(5)\n",
    "        top_five_df = pd.DataFrame(top_five, columns= ['Token', 'Count'])\n",
    "        print(\"\\nFive Most Common Tokens: \\n\\n\", top_five_df)\n",
    "\n",
    "    return([num_tokens, num_unique_tokens,\n",
    "            lexical_diversity,\n",
    "            num_characters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59dcf058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13 tokens in the data.\n",
      "There are 9 unique tokens in the data.\n",
      "There are 55 characters in the data.\n",
      "The lexical diversity is 0.692 in the data.\n",
      "\n",
      "Five Most Common Tokens: \n",
      "\n",
      "      Token  Count\n",
      "0     text      3\n",
      "1     here      2\n",
      "2  example      2\n",
      "3       is      1\n",
      "4     some      1\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"here is some example text with other example text here in this text\"\"\".split()\n",
    "assert(descriptive_stats(text, verbose=True)[0] == 13)\n",
    "assert(descriptive_stats(text, verbose=False)[1] == 9)\n",
    "assert(abs(descriptive_stats(text, verbose=False)[2] - 0.69) < 0.02)\n",
    "assert(descriptive_stats(text, verbose=False)[3] == 55)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e7e1a2",
   "metadata": {},
   "source": [
    "Q: Why is it beneficial to use assertion statements in your code? \n",
    "\n",
    "A: __Assertion statements enables users to test and detect the correctness of the codes and functions by analyzing if some specific conditions remain true.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3bf93e",
   "metadata": {},
   "source": [
    "## Data Input\n",
    "\n",
    "Now read in each of the corpora. For the lyrics data, it may be convenient to store the entire contents of the file to make it easier to inspect the titles individually, as you'll do in the last part of the assignment. In the solution, I stored the lyrics data in a dictionary with two dimensions of keys: artist and song. The value was the file contents. A data frame would work equally well. \n",
    "\n",
    "For the Twitter data, we only need the description field for this assignment. Feel free all the descriptions read it into a data structure. In the solution, I stored the descriptions as a dictionary of lists, with the key being the artist. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37d70801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Song</th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eltonjohn</td>\n",
       "      <td>\"All Across The Havens\"</td>\n",
       "      <td>The sister of sunlight Comes to my lonely l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eltonjohn</td>\n",
       "      <td>\"Border Song\"</td>\n",
       "      <td>Holy Moses, I have been removed I have seen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eltonjohn</td>\n",
       "      <td>\"Empty Sky\"</td>\n",
       "      <td>I'm not a rat to be spat on, locked up in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eltonjohn</td>\n",
       "      <td>\"First Episode At Hienton\"</td>\n",
       "      <td>I was one as you were one And we were two s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eltonjohn</td>\n",
       "      <td>\"Gulliver\"</td>\n",
       "      <td>Gulliver's gone to the final command of his...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>eltonjohn</td>\n",
       "      <td>\"Hymn 2000\"</td>\n",
       "      <td>She chose the soft center And took it to be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>eltonjohn</td>\n",
       "      <td>\"I Need You To Turn To\"</td>\n",
       "      <td>You're not a ship to carry my life You are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>eltonjohn</td>\n",
       "      <td>\"It's Me That You Need\"</td>\n",
       "      <td>Hey there Look in the mirror Are you afraid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>eltonjohn</td>\n",
       "      <td>\"Just Like Strange Rain\"</td>\n",
       "      <td>I looked up from my glass into the sky Ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>eltonjohn</td>\n",
       "      <td>\"Lady Samantha\"</td>\n",
       "      <td>When the shrill winds are screaming And the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Artist                        Song  \\\n",
       "0  eltonjohn     \"All Across The Havens\"   \n",
       "1  eltonjohn               \"Border Song\"   \n",
       "2  eltonjohn                 \"Empty Sky\"   \n",
       "3  eltonjohn  \"First Episode At Hienton\"   \n",
       "4  eltonjohn                  \"Gulliver\"   \n",
       "5  eltonjohn                 \"Hymn 2000\"   \n",
       "6  eltonjohn     \"I Need You To Turn To\"   \n",
       "7  eltonjohn     \"It's Me That You Need\"   \n",
       "8  eltonjohn    \"Just Like Strange Rain\"   \n",
       "9  eltonjohn             \"Lady Samantha\"   \n",
       "\n",
       "                                              Lyrics  \n",
       "0     The sister of sunlight Comes to my lonely l...  \n",
       "1     Holy Moses, I have been removed I have seen...  \n",
       "2     I'm not a rat to be spat on, locked up in t...  \n",
       "3     I was one as you were one And we were two s...  \n",
       "4     Gulliver's gone to the final command of his...  \n",
       "5     She chose the soft center And took it to be...  \n",
       "6     You're not a ship to carry my life You are ...  \n",
       "7     Hey there Look in the mirror Are you afraid...  \n",
       "8     I looked up from my glass into the sky Ther...  \n",
       "9     When the shrill winds are screaming And the...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the lyrics data\n",
    "artists = [\"eltonjohn\", \"nirvana\"]\n",
    "lyrics_filepaths = []\n",
    "artist_list = []\n",
    "\n",
    "for i in artists:\n",
    "\n",
    "    # Set file path for the artists (lyrics) selected\n",
    "    path = data_location + lyrics_folder + i\n",
    "\n",
    "    # Use glob to retrieve file paths recursively from inside the directories/files\n",
    "    txt_files = glob.glob(os.path.normpath(os.path.join(path, \"*.txt\")))\n",
    "\n",
    "    # Create the artists (lyrics) list for df\n",
    "    temp_list = [i] * len(txt_files)\n",
    "    artist_list = artist_list + temp_list\n",
    "\n",
    "    # Combine the artists filepaths\n",
    "    lyrics_filepaths = lyrics_filepaths + txt_files\n",
    "\n",
    "lyrics_list = []\n",
    "song_list = []\n",
    "\n",
    "for file in lyrics_filepaths:\n",
    "\n",
    "    # Song\n",
    "    file_temp = open(file, \"r\")\n",
    "    title = file_temp.readline().rstrip()\n",
    "    song_list.append(title)\n",
    "\n",
    "    # Lyrics\n",
    "    list = file_temp.readlines()[1:]\n",
    "    lyrics = \"\".join(list)\n",
    "    lyrics = lyrics.replace('\\n', \" \")\n",
    "    lyrics_list.append(lyrics)\n",
    "    file_temp.close()\n",
    "\n",
    "# Convert to df\n",
    "dict = {'Artist': artist_list, 'Song': song_list, 'Lyrics': lyrics_list}\n",
    "lyrics_df = pd.DataFrame(dict)\n",
    "\n",
    "lyrics_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "debcac5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>description</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hsmcnp</td>\n",
       "      <td>Country Girl</td>\n",
       "      <td>35152213</td>\n",
       "      <td></td>\n",
       "      <td>1302</td>\n",
       "      <td>1014</td>\n",
       "      <td>None</td>\n",
       "      <td>cher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>horrormomy</td>\n",
       "      <td>Jeny</td>\n",
       "      <td>742153090850164742</td>\n",
       "      <td>Earth</td>\n",
       "      <td>81</td>\n",
       "      <td>514</td>\n",
       "      <td>𝙿𝚛𝚘𝚞𝚍 𝚜𝚞𝚙𝚙𝚘𝚛𝚝𝚎𝚛 𝚘𝚏 𝚖𝚎𝚜𝚜𝚢 𝚋𝚞𝚗𝚜 &amp; 𝚕𝚎𝚐𝚐𝚒𝚗𝚐𝚜</td>\n",
       "      <td>cher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anju79990584</td>\n",
       "      <td>anju</td>\n",
       "      <td>1496463006451974150</td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>140</td>\n",
       "      <td>163㎝／愛かっぷ💜26歳🍒 工〇好きな女の子💓 フォローしてくれたらDMします🧡</td>\n",
       "      <td>cher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gallionjenna</td>\n",
       "      <td>J</td>\n",
       "      <td>3366479914</td>\n",
       "      <td></td>\n",
       "      <td>752</td>\n",
       "      <td>556</td>\n",
       "      <td>csu</td>\n",
       "      <td>cher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bcscomm</td>\n",
       "      <td>bcscomm</td>\n",
       "      <td>83915043</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>888</td>\n",
       "      <td>2891</td>\n",
       "      <td>Writer @Washinformer @SpelmanCollege alumna #D...</td>\n",
       "      <td>cher</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    screen_name          name                   id        location  \\\n",
       "0        hsmcnp  Country Girl             35152213                   \n",
       "1    horrormomy          Jeny   742153090850164742           Earth   \n",
       "2  anju79990584          anju  1496463006451974150                   \n",
       "3  gallionjenna             J           3366479914                   \n",
       "4       bcscomm       bcscomm             83915043  Washington, DC   \n",
       "\n",
       "  followers_count friends_count  \\\n",
       "0            1302          1014   \n",
       "1              81           514   \n",
       "2              13           140   \n",
       "3             752           556   \n",
       "4             888          2891   \n",
       "\n",
       "                                         description artist  \n",
       "0                                               None   cher  \n",
       "1           𝙿𝚛𝚘𝚞𝚍 𝚜𝚞𝚙𝚙𝚘𝚛𝚝𝚎𝚛 𝚘𝚏 𝚖𝚎𝚜𝚜𝚢 𝚋𝚞𝚗𝚜 & 𝚕𝚎𝚐𝚐𝚒𝚗𝚐𝚜   cher  \n",
       "2          163㎝／愛かっぷ💜26歳🍒 工〇好きな女の子💓 フォローしてくれたらDMします🧡   cher  \n",
       "3                                                csu   cher  \n",
       "4  Writer @Washinformer @SpelmanCollege alumna #D...   cher  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the twitter data \n",
    "twitter_location = data_location + twitter_folder\n",
    "twitter_filepaths = glob.glob(os.path.normpath(os.path.join(twitter_location, \"*followers_data.txt\")))\n",
    "res = []\n",
    "artist_list = []\n",
    "\n",
    "for file in twitter_filepaths:\n",
    "\n",
    "    file_temp = open(file, \"r\")\n",
    "    colnames = file_temp.readline().rstrip().split('\\t')\n",
    "    lines = file_temp.readlines()\n",
    "    \n",
    "    for x in lines:\n",
    "        text_temp = x.rstrip().split('\\t')\n",
    "        res.append(text_temp)\n",
    "\n",
    "        # Retrieve the artists for df\n",
    "        art_temp = file[file.rindex('\\\\')+1:]\n",
    "        artist = art_temp.split('_followers')[0]\n",
    "        artist_list.append(artist)\n",
    "        \n",
    "    file_temp.close\n",
    "\n",
    "# Create df\n",
    "twitter_df = pd.DataFrame(res, columns=colnames)\n",
    "twitter_df['artist'] = artist_list\n",
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567f3ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a5f3b12",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Now clean and tokenize your data. Remove punctuation chacters (available in the `punctuation` object in the `string` library), split on whitespace, fold to lowercase, and remove stopwords. Store your cleaned data, which must be accessible as an interable for `descriptive_stats`, in new objects or in new columns in your data frame. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f94aa90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = set(punctuation) # speeds up comparison\n",
    "\n",
    "# First, clean the twitter data.\n",
    "twitter_clean_df = twitter_df.copy()\n",
    "\n",
    "# Tokenize and remove any data missing, punctuations, and lowercase words within the 'description' category\n",
    "twitter_clean_df = twitter_clean_df.dropna()\n",
    "twitter_clean_df['description'] = twitter_clean_df['description'].str.replace('[{}]'.format(string.punctuation), \n",
    "                                                                              '')\n",
    "twitter_clean_df['description'] = twitter_clean_df['description'].str.lower()\n",
    "twitter_clean_df['description'] = twitter_clean_df['description'].str.split()\n",
    "\n",
    "# Remove stopwords to reduce dataset size and training time\n",
    "stop_words = stopwords.words('english')\n",
    "tweet_nostop = twitter_clean_df['description'].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "twitter_clean_df['description'] = tweet_nostop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc727c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, clean the lyrics data\n",
    "lyrics_clean_df = lyrics_df.copy()\n",
    "\n",
    "lyrics_clean_df = lyrics_clean_df.dropna()\n",
    "lyrics_clean_df['Lyrics'] = lyrics_clean_df['Lyrics'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "lyrics_clean_df['Lyrics'] = lyrics_clean_df['Lyrics'].str.lower()\n",
    "lyrics_clean_df['Lyrics'] = lyrics_clean_df['Lyrics'].str.split()\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "lyric_nostop = lyrics_clean_df['Lyrics'].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "lyrics_clean_df['Lyrics'] = lyric_nostop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dd0179",
   "metadata": {},
   "source": [
    "## Basic Descriptive Statistics\n",
    "\n",
    "Call your `descriptive_stats` function on both your lyrics data and your twitter data and for both artists (four total calls)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc17317a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elton John Lyrics Results:\n",
      "\n",
      "There are 2350 tokens in the data.\n",
      "There are 825 unique tokens in the data.\n",
      "There are 11311 characters in the data.\n",
      "The lexical diversity is 0.351 in the data.\n",
      "\n",
      "Five Most Common Tokens: \n",
      "\n",
      "   Token  Count\n",
      "0    na    121\n",
      "1  take     31\n",
      "2  rain     23\n",
      "3  like     22\n",
      "4   one     22\n",
      "[2350, 825, 0.35106382978723405, 11311]\n",
      "\n",
      "Nirvana Lyrics Results:\n",
      "\n",
      "There are 2157 tokens in the data.\n",
      "There are 482 unique tokens in the data.\n",
      "There are 10362 characters in the data.\n",
      "The lexical diversity is 0.223 in the data.\n",
      "\n",
      "Five Most Common Tokens: \n",
      "\n",
      "   Token  Count\n",
      "0  dont     85\n",
      "1    im     79\n",
      "2  girl     52\n",
      "3  yeah     48\n",
      "4  said     38\n",
      "[2157, 482, 0.22345850718590635, 10362]\n"
     ]
    }
   ],
   "source": [
    "# calls to descriptive_stats here\n",
    "\n",
    "# twitter - cher\n",
    "# cher = twitter_clean[twitter_clean['artist'] == 'cher']\n",
    "# cher_corpus = [element for list_ in cher['description'].values for element in list_]\n",
    "# print(\"\\nCher Twitter Results:\\n\")\n",
    "# print(descriptive_stats(cher_corpus))\n",
    "\n",
    "# twitter - robynkonichiwa\n",
    "# rob = twitter_clean[twitter_clean['artist'] == 'robynkonichiwa']\n",
    "# rob_corpus = [element for list_ in rob['description'].values for element in list_]\n",
    "# print(\"\\nrobynkonichiwa Twitter Results:\\n\")\n",
    "# print(descriptive_stats(rob_corpus))\n",
    "\n",
    "# lyrics - Elton John\n",
    "eltonjohn = lyrics_clean_df[lyrics_clean_df['Artist'] == 'eltonjohn']\n",
    "eltonjohn_corpus = [element for list_ in eltonjohn['Lyrics'].values for element in list_]\n",
    "print(\"Elton John Lyrics Results:\\n\")\n",
    "print(descriptive_stats(eltonjohn_corpus))\n",
    "\n",
    "# lyrics - Nirvana\n",
    "nirvana = lyrics_clean_df[lyrics_clean_df['Artist'] == 'nirvana']\n",
    "nirvana_corpus = [element for list_ in nirvana['Lyrics'].values for element in list_]\n",
    "print(\"\\nNirvana Lyrics Results:\\n\")\n",
    "print(descriptive_stats(nirvana_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46294409",
   "metadata": {},
   "source": [
    "Q: How do you think the \"top 5 words\" would be different if we left stopwords in the data? \n",
    "\n",
    "A: __A key difference that would be noted towards the top 5 words if the stopwords were left in the data would be that the data or list of top 5 words would contain words that are noisy or misproperly formatted. Leaving stop words would not add analytical context towards the information within the data that are important and they would not enable users to assess the context of a sentence.__ \n",
    "\n",
    "Q: What were your prior beliefs about the lexical diversity between the artists? Does the difference (or lack thereof) in lexical diversity between the artists conform to your prior beliefs? \n",
    "\n",
    "A: __My initial belief prior to this assignment was that each of the artists would generate a high amount of lexical diversity amongst each of their respective songs and lyrcis. After analyzing, dissecting, and cleaning the data between the artists, I am surprised that there is not much lexical diversity amongst the artists. Another note that surprised me was the number of token words that generated while not in proper format, which leads to the idea of labeling the words as stop words and tokenizing them while cleaning the data more in the future.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4e1ac1",
   "metadata": {},
   "source": [
    "\n",
    "## Specialty Statistics\n",
    "\n",
    "The descriptive statistics we have calculated are quite generic. You will now calculate a handful of statistics tailored to these data.\n",
    "\n",
    "1. Ten most common emojis by artist in the twitter descriptions.\n",
    "1. Ten most common hashtags by artist in the twitter descriptions.\n",
    "1. Five most common words in song titles by artist. \n",
    "1. For each artist, a histogram of song lengths (in terms of number of tokens) \n",
    "\n",
    "We can use the `emoji` library to help us identify emojis and you have been given a function to help you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "753a5a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(emoji.is_emoji(\"❤️\"))\n",
    "assert(not emoji.is_emoji(\":-)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986fc4c0",
   "metadata": {},
   "source": [
    "### Emojis 😁\n",
    "\n",
    "What are the ten most common emojis by artist in the twitter descriptions? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "269cd433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cher Emoji Results:\n",
      " emoji\n",
      "['♥']    10152\n",
      "['❤']     9653\n",
      "['✨']     8343\n",
      "['🌈']     5482\n",
      "['💙']     3685\n",
      "['💜']     3499\n",
      "['🌊']     3291\n",
      "['💕']     3259\n",
      "['🖤']     2937\n",
      "['🎶']     2384\n",
      "Name: emoji, dtype: int64\n",
      "\n",
      "robynkonichiwa Emoji Results:\n",
      " emoji\n",
      "['♥']    1166\n",
      "['✨']     751\n",
      "['❤']     652\n",
      "['🌈']     570\n",
      "['🎶']     272\n",
      "['🎧']     213\n",
      "['🖤']     212\n",
      "['💜']     205\n",
      "['💙']     181\n",
      "['🐶']     166\n",
      "Name: emoji, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# cher\n",
    "emoji_list = emoji.emoji_list(cher_corpus)\n",
    "emoji_df = pd.DataFrame(emoji_list)\n",
    "emoji_df['emoji'] = emoji_df['emoji'].astype(str)\n",
    "cher_res = emoji_df.groupby('emoji')['emoji'].count().sort_values(ascending=False).head(10)\n",
    "print('cher Emoji Results:\\n', cher_res)\n",
    "\n",
    "# robynkonichiwa\n",
    "emoji_list = emoji.emoji_list(rob_corpus)\n",
    "emoji_df = pd.DataFrame(emoji_list)\n",
    "emoji_df['emoji'] = emoji_df['emoji'].astype(str)\n",
    "rob_res = emoji_df.groupby('emoji')['emoji'].count().sort_values(ascending=False).head(10)\n",
    "print('\\nrobynkonichiwa Emoji Results:\\n', rob_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab9b770",
   "metadata": {},
   "source": [
    "### Hashtags\n",
    "\n",
    "What are the ten most common hashtags by artist in the twitter descriptions? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07c396f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cher Hashtag Results:\n",
      "\n",
      "              hashtags  count\n",
      "29             #resist   9558\n",
      "14                #blm   8753\n",
      "3    #blacklivesmatter   7432\n",
      "45                #fbr   2922\n",
      "1       #theresistance   2883\n",
      "85         #resistance   2405\n",
      "105                 #1   2226\n",
      "86                   #   1965\n",
      "249          #voteblue   1897\n",
      "528             #lgbtq   1457\n",
      "\n",
      "robynknoichiwa Hashtag Results:\n",
      "\n",
      "              hashtags  count\n",
      "71   #blacklivesmatter    563\n",
      "29                #blm    324\n",
      "105             #music    260\n",
      "39                  #1    187\n",
      "871                  #    150\n",
      "573    #teamfollowback    117\n",
      "767               #edm    104\n",
      "240            #resist     76\n",
      "540       #freebritney     63\n",
      "392             #lgbtq     58\n"
     ]
    }
   ],
   "source": [
    "twitter_ht = twitter_df.copy()\n",
    "twitter_ht = twitter_ht.dropna()\n",
    "twitter_ht['description'] = twitter_ht['description'].str.lower()\n",
    "twitter_ht['description'] = twitter_ht['description'].str.split()\n",
    "\n",
    "cher_ht = twitter_ht[twitter_ht['artist'] == 'cher']\n",
    "cher_corpus_ht = [element for list_ in cher_ht['description'].values for element in list_]\n",
    "\n",
    "rob_ht = twitter_ht[twitter_ht['artist'] == 'robynkonichiwa']\n",
    "rob_corpus_ht = [element for list_ in rob_ht['description'].values for element in list_]\n",
    "\n",
    "#cher\n",
    "cher_ht_list = [i for i in cher_corpus_ht if i.startswith(\"#\")]\n",
    "cher_count = Counter(cher_ht_list)\n",
    "df = pd.DataFrame.from_dict(cher_count, orient='index').reset_index()\n",
    "df = df.rename(columns={'index' : 'hashtags', 0:'count'})\n",
    "\n",
    "cher_res = df.sort_values(by='count', ascending=False).head(10)\n",
    "print(\"Cher Hashtag Results:\\n\")\n",
    "print(cher_res)\n",
    "\n",
    "# robynkonichiwa\n",
    "rob_ht_list = [i for i in rob_corpus_ht if i.startswith(\"#\")]\n",
    "rob_count = Counter(rob_ht_list)\n",
    "df = pd.DataFrame.from_dict(rob_count, orient='index').reset_index()\n",
    "df = df.rename(columns={'index' : 'hashtags', 0:'count'})\n",
    "\n",
    "rob_res = df.sort_values(by='count', ascending=False).head(10)\n",
    "print(\"\\nrobynknoichiwa Hashtag Results:\\n\")\n",
    "print(rob_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10f21d5",
   "metadata": {},
   "source": [
    "### Song Titles\n",
    "\n",
    "What are the five most common words in song titles by artist? The song titles should be on the first line of the lyrics pages, so if you have kept the raw file contents around, you will not need to re-read the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb69b36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stitle_clean = lyrics_df.copy()\n",
    "stitle_clean = stitle_clean.dropna()\n",
    "stitle_clean['Song'] = stitle_clean['Song'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "stitle_clean['Song'] = stitle_clean['Song'].str.lower()\n",
    "stitle_clean['Song'] = stitle_clean['Song'].str.split()\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stitle_nostop = stitle_clean['Song'].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "stitle_clean['Song'] = stitle_nostop\n",
    "\n",
    "# elton john\n",
    "eltonjohn = stitle_clean[stitle_clean['Artist'] == 'eltonjohn']\n",
    "eltonjohn_corpus = [element for list_ in eltonjohn['Song'].values for element in list_]\n",
    "\n",
    "# nirvana\n",
    "nirvana = stitle_clean[stitle_clean['Artist'] == 'nirvana']\n",
    "nirvana_corpus = [element for list_ in nirvana['Song'].values for element in list_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b19fe86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elton JOhn Title Results:\n",
      "\n",
      "       word  count\n",
      "17     lady      2\n",
      "3      song      2\n",
      "12     need      2\n",
      "0    across      1\n",
      "27  skyline      1\n",
      "22  strings      1\n",
      "23   louise      1\n",
      "24    sails      1\n",
      "25    sixty      1\n",
      "26    years      1\n",
      "\n",
      "Nirvana Song Title Results:\n",
      "\n",
      "           word  count\n",
      "0          girl      1\n",
      "16        creep      1\n",
      "29  territorial      1\n",
      "28         meet      1\n",
      "27         swap      1\n",
      "26       spirit      1\n",
      "25         teen      1\n",
      "24         like      1\n",
      "23       smells      1\n",
      "22      sifting      1\n"
     ]
    }
   ],
   "source": [
    "# elton john\n",
    "eltonjohn_wordcount = Counter(eltonjohn_corpus)\n",
    "df = pd.DataFrame.from_dict(eltonjohn_wordcount, orient='index').reset_index()\n",
    "df = df.rename(columns={'index' : 'word', 0:'count'})\n",
    "\n",
    "eltonjohn = df.sort_values(by='count', ascending=False).head(10)\n",
    "print(\"Elton JOhn Title Results:\\n\")\n",
    "print(eltonjohn)\n",
    "\n",
    "# nirvana\n",
    "nirvana_wordcount = Counter(nirvana_corpus)\n",
    "df = pd.DataFrame.from_dict(nirvana_wordcount, orient='index').reset_index()\n",
    "df = df.rename(columns={'index' : 'word', 0:'count'})\n",
    "\n",
    "nirvana = df.sort_values(by='count', ascending=False).head(10)\n",
    "print(\"\\nNirvana Song Title Results:\\n\")\n",
    "print(nirvana)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd4fd71",
   "metadata": {},
   "source": [
    "### Song Lengths\n",
    "\n",
    "For each artist, a histogram of song lengths (in terms of number of tokens). If you put the song lengths in a data frame with an artist column, matplotlib will make the plotting quite easy. An example is given to help you out. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "805a1e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist\n",
       "Artist 1    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "Artist 2    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "Name: length, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_replicates = 1000\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"artist\" : ['Artist 1'] * num_replicates + ['Artist 2']*num_replicates,\n",
    "    \"length\" : np.concatenate((np.random.poisson(125,num_replicates),np.random.poisson(150,num_replicates)))\n",
    "})\n",
    "\n",
    "df.groupby('artist')['length'].plot(kind=\"hist\",density=True,alpha=0.5,legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fde9ebb",
   "metadata": {},
   "source": [
    "Since the lyrics may be stored with carriage returns or tabs, it may be useful to have a function that can collapse whitespace, using regular expressions, and be used for splitting. \n",
    "\n",
    "Q: What does the regular expression `'\\s+'` match on? \n",
    "\n",
    "A: __The `'\\s+'` regular expression matches on to one or more whitespace characters.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0e34516",
   "metadata": {},
   "outputs": [],
   "source": [
    "collapse_whitespace = re.compile(r'\\s+')\n",
    "\n",
    "def tokenize_lyrics(lyric) : \n",
    "    \"\"\"strip and split on whitespace\"\"\"\n",
    "    return([item.lower() for item in collapse_whitespace.split(lyric)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2294c440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Artist\n",
       "eltonjohn    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "nirvana      AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "Name: length, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lyric length comparison chart\n",
    "hist_df = lyrics_df.copy()\n",
    "\n",
    "# Tokenize for song/lyric length\n",
    "hist_df['Lyrics'] = hist_df['Lyrics'].apply(tokenize_lyrics)\n",
    "hist_df['length'] = hist_df['Lyrics'].apply(len)\n",
    "\n",
    "# Plot histogram\n",
    "hist_df.groupby('Artist')['length'].plot(kind=\"hist\",density=True,alpha=0.5,legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4034883",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
